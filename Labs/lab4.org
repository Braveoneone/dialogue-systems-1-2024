#+TITLE: Lab IV. Natural language understanding

* Task 1: Integrate a statistical NLU in your dialogue system
In lab 2 (basic dialogue management), you used a simplistic mapping (called "grammar" in the code) from user utterances to intents and entities. In the first task of this lab, you will replace this grammar with a statistical NLU trained and deployed using Conversational Language Understanding (CLU) in Azure.

** 1) Create a NLU project in Azure
  Go to https://language.cognitive.azure.com/ and ensure that you are signed in with your Azure account. 
  Choose Create new -> Conversational language understanding. As part of this, you may need to create a new Azure language resource. 
  Note that resource names are unique across the entire Azure platform, so you may need to include some arbitrary digits or numbers in it (e.g. language_resource_57372).

  As project name, you can e.g. enter: *appointment*.

** 2) Add intents 
  In the "Schema definition" menu of your project you will find the option to create Intents and Entities. Intents are a result of automatic classification of sentences (or expressions) performed by a model/machine. 
  In order to get the model to recognize your intents, you will have to train them first with examples of what sentences with such intents look like. The model will avarage those sentences to infer your intents. We won't use entities until point (6).

- Example:
  - Intent: Book a restaurant
  - Example utterance: "I'd like to make a reservation for tonight."
  - Example utterance: "Find me a good Italian place nearby."

First, create two intents, corresponding to "create a meeting" and "who is X" (X= name of a famous person). Make sure to use the same names for these intents as you do in your code. 
Then, choose "Data labeling" in the navigation menu to the left and add around 10 training examples for each intent. (At this stage, you can come up with examples on your own. You can improve the training data later.)

  To train the model for the first time, choose "Training jobs" in the navigation menu and select "Train a new model". As model name, you can choose *appointment*. (When you re-train the model later on, select "Overwrite an existing model".)

** 3) Deploy the model
  In order to use your trained model in your dialogue system, you first need to deploy it. Choose "Deploying a model" in the navigation menu and then "Add deployment". Again, as deployment name you can choose *appointment*. (When you re-train your model later on and want to re-deploy it, overwrite the existing deployment name.)

** 4) Integrate the model

Configure your NLU by adding the following to your file:

- create a NLU_KEY const in your azure.js file and import it (together with your KEY).
- create the object "azureLanguageCredentials":

#+BEGIN_EXAMPLE
const azureLanguageCredentials = {
  endpoint:
    "https://speechstate.cognitiveservices.azure.com/language/:analyze-conversations?api-version=2022-10-01-preview",
  key: NLU_KEY /** your Azure CLU key */,
  deploymentName: "" /** your Azure CLU deployment */,
  projectName: "" /** your Azure CLU project name */,
};
#+END_EXAMPLE

- To your "settings" const add said object:

#+BEGIN_EXAMPLE
const settings = {
  azureLanguageCredentials: azureLanguageCredentials /** global activation of NLU */,
  azureCredentials: azureCredentials,
  asrDefaultCompleteTimeout: 0,
  asrDefaultNoInputTimeout: 5000,
  locale: "en-US",
  ttsDefaultVoice: "en-US-DavisNeural",
};
#+END_EXAMPLE

- *Don't forget to go to your main.js file and change where you import setuptButton from, in case you are using a file named differently than "dm.js".*

Finally, you need to rewire the logic in your code that concerns intents and entities:
- *Results from CLU are available in the field "nluResult" in the context (context.nluResult).*
You can use those in your conditions. This is used instead of working with a grammar checking function.

** 5) Test
Validate via manual testing that your dialogue system now uses your deployed NLU model rather than the old "grammar". At this stage, note that only the two intents are supported, and no entities. This is fine for now.

** 6) Adding entities
Go back to "Schema definition" and add the entities that you need, e.g. for meeting title, meeting time, yes/no, etc. Again, choose entity names corresponding to those in your code.

Note that CLU supports different methods for extracting entities. You will need to choose the most relevant method for each entity.

Note also that meeting title is a bit trickier than other entities, since almost anything can be a title. Don't worry about choosing the "wrong" method for an entity; whatever method you choose, you can always improve things later.

* Task 2: Improve NLU
Based on insights from testing your own system, and from having the system tested by peer students, you should now try to improve NLU coverage. There are no specific requirements concerning how much coverage you need. You are not expected to spend more than an hour on this task.

* Submission
Export your NLU project by choosing "Projects" in the navigation menu to the left, then select your project and click Export. (You might need to unblock a pop-up window.) Save the exported content as a JSON file (.json extension).

Submit:
- link to your forked repo
